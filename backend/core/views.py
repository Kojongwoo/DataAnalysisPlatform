# backend/core/views.py

import pandas as pd
import io
import numpy as np
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework.parsers import MultiPartParser, JSONParser

# --- í—¬í¼ í•¨ìˆ˜ ---
def _analyze_dataframe(df):
    """
    ì£¼ì–´ì§„ DataFrameì„ ë¶„ì„í•˜ì—¬ table, stats, quality JSONì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # 1. ì „ì²´ í…Œì´ë¸” ë°ì´í„°
    table_json = df.astype(object).fillna('-').to_json(orient='split', force_ascii=False)

    # --- ğŸ’¡ 2. ê¸°ì´ˆ í†µê³„ëŸ‰ ë°ì´í„° (ìˆ˜ì •ë¨) ---
    # (1) ê¸°ë³¸ describe ìˆ˜í–‰
    stats_df = df.describe(include='all')
    
    # (2) ë°ì´í„° íƒ€ì…(Data Type) í–‰ ìƒì„±
    # ê° ì»¬ëŸ¼ì´ ìˆ˜ì¹˜í˜•ì¸ì§€ ì•„ë‹Œì§€ íŒë³„
    dtype_data = {}
    for col in df.columns:
        if pd.api.types.is_numeric_dtype(df[col]):
            dtype_data[col] = 'Numeric (ìˆ˜ì¹˜í˜•)'
        else:
            dtype_data[col] = 'Categorical (ë²”ì£¼í˜•)'
            
    # DataFrameìœ¼ë¡œ ë³€í™˜ (ì¸ë±ìŠ¤ ì´ë¦„ì€ 'Data Type')
    dtype_df = pd.DataFrame([dtype_data], index=['Data Type'])
    
    # (3) ê¸°ì¡´ í†µê³„ëŸ‰ ë§¨ ìœ„ì— 'Data Type' í–‰ í•©ì¹˜ê¸°
    stats_df = pd.concat([dtype_df, stats_df])
    
    # (4) ì¸ë±ìŠ¤ ì´ˆê¸°í™” ë° JSON ë³€í™˜ (ê¸°ì¡´ ë¡œì§)
    stats_df = stats_df.reset_index() # 'index' ì»¬ëŸ¼ì´ ìƒì„±ë¨ (Data Type, count, mean...)
    stats_df.rename(columns={'index': 'êµ¬ë¶„'}, inplace=True) # ë³´ê¸° ì¢‹ê²Œ ì´ë¦„ ë³€ê²½
    
    stats_json = stats_df.astype(object).fillna('-').to_json(orient='split', force_ascii=False)
    # --------------------------------------

    # 3. ë°ì´í„° í’ˆì§ˆ ë°ì´í„°
    total_rows = len(df)
    
    missing_counts = df.isnull().sum()

    if total_rows > 0:
        missing_percent = (missing_counts / total_rows * 100).round(2)
    else:
        missing_percent = pd.Series(0.0, index=df.columns)
    
    outlier_counts = pd.Series('-', index=df.columns)
    outlier_percent = pd.Series('-', index=df.columns)
    
    # ìˆ˜ì¹˜í˜• ë³€í™˜ ì‹œë„ (ì´ìƒì¹˜ ê³„ì‚°ì„ ìœ„í•´)
    # object íƒ€ì…ì´ë¼ë„ ìˆ«ìë¡œ ë³€í™˜ ê°€ëŠ¥í•˜ë‹¤ë©´ ë³€í™˜í•´ì„œ ê³„ì‚°
    # ğŸ’¡ ìˆ˜ì •: errors='ignore' ëŒ€ì‹  coerceë¡œ ê°•ì œ ë³€í™˜ í›„ ìˆ˜ì¹˜í˜•ë§Œ ì„ íƒ
    df_numeric = df.copy()
    for col in df_numeric.columns:
        try:
            df_numeric[col] = pd.to_numeric(df_numeric[col], errors='coerce')
        except:
            pass
            
    numeric_cols = df_numeric.select_dtypes(include=[np.number]).columns
    
    for col in numeric_cols:
        Q1 = df_numeric[col].quantile(0.25)
        Q3 = df_numeric[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - (1.5 * IQR)
        upper_bound = Q3 + (1.5 * IQR)
        
        count = ((df_numeric[col] < lower_bound) | (df_numeric[col] > upper_bound)).sum()
        outlier_counts[col] = count

        if total_rows > 0:
            outlier_percent[col] = (count / total_rows * 100).round(2)
        else:
            outlier_percent[col] = 0.0
        
    quality_df = pd.DataFrame({
        'ê²°ì¸¡ì¹˜ ê°œìˆ˜': missing_counts,
        'ê²°ì¸¡ì¹˜ ë¹„ìœ¨(%)': missing_percent,
        'ì´ìƒì¹˜ ê°œìˆ˜': outlier_counts,
        'ì´ìƒì¹˜ ë¹„ìœ¨(%)': outlier_percent
    })
    
    quality_df = quality_df.transpose().reset_index()
    quality_df.rename(columns={'index': 'êµ¬ë¶„'}, inplace=True)

    quality_df.replace(np.nan, '-', inplace=True)
    
    # ğŸ’¡ ìˆ˜ì •: ê²½ê³  ë°©ì§€
    quality_json = quality_df.astype(object).fillna('-').to_json(orient='split', force_ascii=False)

    return {
        'tableData': table_json,
        'statsData': stats_json,
        'qualityData': quality_json
    }

class FileUploadView(APIView):
    parser_classes = (MultiPartParser,)

    def post(self, request, *args, **kwargs):
        file_obj = request.FILES.get('file')

        if not file_obj:
            return Response({"error": "íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."}, status=400)

        try:
            file_buffer = io.BytesIO(file_obj.read())

            if file_obj.name.endswith(('.xls', '.xlsx')):
                df = pd.read_excel(file_buffer)
            elif file_obj.name.endswith('.csv'):
                try:
                    df = pd.read_csv(file_buffer)
                except UnicodeDecodeError:
                    file_buffer.seek(0)
                    df = pd.read_csv(file_buffer, encoding='cp949')
            else:
                return Response({"error": "ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤."}, status=400)

            response_data = _analyze_dataframe(df)
            response_data['fullData'] = df.to_json(orient='split', force_ascii=False)
            
            return Response(response_data)

        except Exception as e:
            return Response({"error": f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}, status=500)

class ProcessDataView(APIView):
    parser_classes = (JSONParser,)
    
    def post(self, request, *args, **kwargs):
        df_json = request.data.get('dataframe')
        action = request.data.get('action')

        if not df_json:
            return Response({"error": "DataFrameì´ ìš”ì²­ì— í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}, status=400)
        
        try:
            # DataFrame ë³µì›
            df = pd.read_json(io.StringIO(df_json), orient='split')
            original_rows = len(df)
            
            # 1. ë¹ˆ ë¬¸ìì—´ -> NaN ì¹˜í™˜
            df.replace("", np.nan, inplace=True)

            # 2. ìˆ˜ì¹˜í˜• ë³€í™˜ ì‹œë„
            for col in df.columns:
                try:
                    df[col] = pd.to_numeric(df[col])
                except (ValueError, TypeError):
                    pass

            if action == 'drop_na':
                df = df.dropna()
                print(f"ê²°ì¸¡ì¹˜ í–‰ ì œê±°: {original_rows} -> {len(df)}")
            
            elif action == 'fill_na_mean':
                numeric_cols = df.select_dtypes(include=[np.number]).columns
                if len(numeric_cols) > 0:
                    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())
                    print(f"ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ í‰ê· ê°’ ëŒ€ì²´ ì™„ë£Œ: {list(numeric_cols)}")
                # ğŸ’¡ ì£¼ì˜: ë¬¸ìì—´ ì»¬ëŸ¼ì€ ì—¬ê¸°ì„œ ì²˜ë¦¬ë˜ì§€ ì•ŠìŒ

            elif action == 'fill_na_median':
                numeric_cols = df.select_dtypes(include=[np.number]).columns
                if len(numeric_cols) > 0:
                    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())
                    print(f"ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì¤‘ì•™ê°’ ëŒ€ì²´ ì™„ë£Œ: {list(numeric_cols)}")

            # --- ğŸ’¡ [ì‹ ê·œ ì¶”ê°€] ìµœë¹ˆê°’(Mode)ìœ¼ë¡œ ì±„ìš°ê¸° ---
            elif action == 'fill_na_mode':
                # ëª¨ë“  ì»¬ëŸ¼ì„ ìˆœíšŒí•˜ë©° ê²°ì¸¡ì¹˜ê°€ ìˆìœ¼ë©´ ìµœë¹ˆê°’ìœ¼ë¡œ ì±„ì›€
                filled_cols = []
                for col in df.columns:
                    if df[col].isnull().sum() > 0:
                        # ìµœë¹ˆê°’ì´ ì—¬ëŸ¬ ê°œì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì²« ë²ˆì§¸([0])ë¥¼ ì„ íƒ
                        mode_value = df[col].mode()[0]
                        df[col] = df[col].fillna(mode_value)
                        filled_cols.append(col)
                print(f"ìµœë¹ˆê°’ ëŒ€ì²´ ì™„ë£Œ (ëŒ€ìƒ ì»¬ëŸ¼): {filled_cols}")

            elif action == 'fill_na_zero':
                df.fillna(0, inplace=True)
                print("ëª¨ë“  ì»¬ëŸ¼ 0ìœ¼ë¡œ ëŒ€ì²´ ì™„ë£Œ")

            # --- ğŸ’¡ [ì‹ ê·œ ì¶”ê°€] ì´ìƒì¹˜ ì²˜ë¦¬ ë¡œì§ ---
            elif action == 'drop_outliers':
                # IQR ë°©ì‹ìœ¼ë¡œ ì´ìƒì¹˜ ì‹ë³„ í›„ ì œê±°
                numeric_cols = df.select_dtypes(include=[np.number]).columns
                Q1 = df[numeric_cols].quantile(0.25)
                Q3 = df[numeric_cols].quantile(0.75)
                IQR = Q3 - Q1
                
                # ì¡°ê±´: (ê°’ < Lower) ë˜ëŠ” (ê°’ > Upper) ì¸ ë°ì´í„°ê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ” í–‰ ì œê±°
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                # any(axis=1)ì€ "ê° í–‰ì— ëŒ€í•´ í•˜ë‚˜ë¼ë„ Trueê°€ ìˆìœ¼ë©´ True"
                outlier_condition = ((df[numeric_cols] < lower_bound) | (df[numeric_cols] > upper_bound)).any(axis=1)
                
                original_rows = len(df)
                df = df[~outlier_condition] # Outlierê°€ ì•„ë‹Œ ê²ƒë§Œ ë‚¨ê¹€
                print(f"ì´ìƒì¹˜ í¬í•¨ í–‰ ì œê±°: {original_rows} -> {len(df)}")

            elif action == 'cap_outliers':
                # ìœˆì €ë¼ì´ì§• (Capping): ì´ìƒì¹˜ë¥¼ ìƒí•œê°’/í•˜í•œê°’ìœ¼ë¡œ ëŒ€ì²´
                numeric_cols = df.select_dtypes(include=[np.number]).columns
                Q1 = df[numeric_cols].quantile(0.25)
                Q3 = df[numeric_cols].quantile(0.75)
                IQR = Q3 - Q1
                
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                for col in numeric_cols:
                    # í•˜í•œê°’ë³´ë‹¤ ì‘ì€ ê°’ì€ í•˜í•œê°’ìœ¼ë¡œ ì¹˜í™˜
                    df[col] = np.where(df[col] < lower_bound[col], lower_bound[col], df[col])
                    # ìƒí•œê°’ë³´ë‹¤ í° ê°’ì€ ìƒí•œê°’ìœ¼ë¡œ ì¹˜í™˜
                    df[col] = np.where(df[col] > upper_bound[col], upper_bound[col], df[col])
                print("ì´ìƒì¹˜ ìœˆì €ë¼ì´ì§•(Capping) ì™„ë£Œ")
            
            else:
                return Response({"error": "ì•Œ ìˆ˜ ì—†ëŠ” ì‘ì—… ìš”ì²­ì…ë‹ˆë‹¤."}, status=400)

            response_data = _analyze_dataframe(df)
            response_data['fullData'] = df.to_json(orient='split', force_ascii=False)
            
            return Response(response_data)

        except Exception as e:
            import traceback
            traceback.print_exc()
            return Response({"error": f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}, status=500)